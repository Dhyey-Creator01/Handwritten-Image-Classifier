{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UlIeBZtVSsS"
   },
   "source": [
    "# Handwritten Digit Image Classifier\n",
    "\n",
    "This notebook trains a Convolutional Neural Network (CNN) on the MNIST dataset to recognize handwritten digits (0‚Äì9).  \n",
    "It then demonstrates inference on custom images, handling dark or light backgrounds automatically.\n",
    "\n",
    "**Key steps:**\n",
    "1. Load and explore MNIST data  \n",
    "2. Preprocess (reshape, normalize)  \n",
    "3. Build CNN architecture (`Conv2D` ‚Üí `MaxPooling` ‚Üí `Flatten` ‚Üí `Dense`)  \n",
    "4. Compile, train, and evaluate model  \n",
    "5. Load external image(s), preprocess, and predict  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Exploration\n",
    "\n",
    "We begin by loading the MNIST dataset from Keras.  \n",
    "- `x_train`, `x_test` are images (28√ó28 pixels).  \n",
    "- `y_train`, `y_test` are integer labels 0‚Äì9.  \n",
    "\n",
    "Below we inspect shapes and visualize one sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wYZnT-OvYeRS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we load the Mnist data from Keras\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "#get an idea of shape of train data\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5dHimADmYfN2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20dc05d4200>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Here we preview an element of the data\n",
    "import matplotlib.pyplot as plt\n",
    " # Only use this if using iPython\n",
    "image_index = 32143 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # To display the label number\n",
    "plt.imshow(x_train[image_index], cmap='Greys') #to show the image associated with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  21, 132, 233,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,  82, 223, 253, 111,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 254, 253, 244,  40,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  21, 142, 253, 252, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  21, 214, 253, 244,  81,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 183, 253, 252, 122,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 113, 253, 254, 172,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         21, 142, 233, 252,  91,  10,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        214, 253, 254, 112,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 142,\n",
       "        253, 252, 192,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 173, 253,\n",
       "        244, 162,   0,   0,  31,  92,  82,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  21, 203, 253, 252,\n",
       "         81,   0,   0,  82, 193, 252, 243,  81,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 253, 254, 151,\n",
       "          0,   0, 113, 253, 254, 253, 254, 151,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  82, 233, 252, 192,  50,\n",
       "          0,  41, 193, 252, 192, 151, 253, 111,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  72, 253, 254, 172,   0,   0,\n",
       "         31, 233, 254, 172,  92, 233, 203,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  41, 233, 252, 233,  30,   0,   0,\n",
       "        173, 252, 233,  71, 233, 252,  81,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 102, 255, 253,  41,   0,  11, 173,\n",
       "        254, 253, 234, 233, 244,  81,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 102, 253, 252,  82,   0,  92, 252,\n",
       "        253, 252, 253, 252,  81,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 102, 255, 253, 255, 253, 254, 253,\n",
       "        254, 253, 183,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  20, 112, 192, 213, 252, 233, 192,\n",
       "        151,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[image_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Before training a neural network, we need to prepare the image data in a format suitable for deep learning. This includes reshaping, type conversion, and normalization.\n",
    "\n",
    "---\n",
    "\n",
    "###  Reshaping the Input\n",
    "\n",
    "The MNIST dataset originally has shapes:\n",
    "\n",
    "- `x_train.shape ‚Üí (60000, 28, 28)`  \n",
    "- `x_test.shape ‚Üí (10000, 28, 28)`\n",
    "\n",
    "This means:\n",
    "- 60,000 training images and 10,000 test images  \n",
    "- Each image is 28√ó28 pixels  \n",
    "- But there is **no channel dimension** (i.e., color information)\n",
    "\n",
    "#### ‚û§ Why reshape to `(28, 28, 1)`?\n",
    "\n",
    "CNNs expect input in the format:  \n",
    "**`(samples, height, width, channels)`**\n",
    "\n",
    "- The `1` at the end indicates these are **grayscale images** (1 channel), unlike RGB images which have 3 channels.\n",
    "- Reshaping ensures compatibility with layers like `Conv2D`, which require 4D input.\n",
    "- Without this step, the model would raise a shape mismatch error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VwRdn1KnYfeB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "#Reshaping and preprocessing\n",
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.5176471 ],\n",
       "        [0.9137255 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.32156864],\n",
       "        [0.8745098 ],\n",
       "        [0.99215686],\n",
       "        [0.43529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.15686275],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.5568628 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.47843137],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.8392157 ],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7176471 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.47843137],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.44313726],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.6745098 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.5568628 ],\n",
       "        [0.9137255 ],\n",
       "        [0.9882353 ],\n",
       "        [0.35686275],\n",
       "        [0.03921569],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.8392157 ],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.4392157 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.5568628 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.7529412 ],\n",
       "        [0.19607843],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.6784314 ],\n",
       "        [0.99215686],\n",
       "        [0.95686275],\n",
       "        [0.63529414],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.12156863],\n",
       "        [0.36078432],\n",
       "        [0.32156864],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.08235294],\n",
       "        [0.79607844],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.32156864],\n",
       "        [0.75686276],\n",
       "        [0.9882353 ],\n",
       "        [0.9529412 ],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.44313726],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.5921569 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.44313726],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.5921569 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.32156864],\n",
       "        [0.9137255 ],\n",
       "        [0.9882353 ],\n",
       "        [0.7529412 ],\n",
       "        [0.19607843],\n",
       "        [0.        ],\n",
       "        [0.16078432],\n",
       "        [0.75686276],\n",
       "        [0.9882353 ],\n",
       "        [0.7529412 ],\n",
       "        [0.5921569 ],\n",
       "        [0.99215686],\n",
       "        [0.43529412],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.28235295],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.6745098 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.12156863],\n",
       "        [0.9137255 ],\n",
       "        [0.99607843],\n",
       "        [0.6745098 ],\n",
       "        [0.36078432],\n",
       "        [0.9137255 ],\n",
       "        [0.79607844],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.16078432],\n",
       "        [0.9137255 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9137255 ],\n",
       "        [0.11764706],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.6784314 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9137255 ],\n",
       "        [0.2784314 ],\n",
       "        [0.9137255 ],\n",
       "        [0.9882353 ],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [1.        ],\n",
       "        [0.99215686],\n",
       "        [0.16078432],\n",
       "        [0.        ],\n",
       "        [0.04313726],\n",
       "        [0.6784314 ],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.91764706],\n",
       "        [0.9137255 ],\n",
       "        [0.95686275],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.32156864],\n",
       "        [0.        ],\n",
       "        [0.36078432],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.99215686],\n",
       "        [0.9882353 ],\n",
       "        [0.31764707],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [1.        ],\n",
       "        [0.99215686],\n",
       "        [1.        ],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.99607843],\n",
       "        [0.99215686],\n",
       "        [0.7176471 ],\n",
       "        [0.07843138],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07843138],\n",
       "        [0.4392157 ],\n",
       "        [0.7529412 ],\n",
       "        [0.8352941 ],\n",
       "        [0.9882353 ],\n",
       "        [0.9137255 ],\n",
       "        [0.7529412 ],\n",
       "        [0.5921569 ],\n",
       "        [0.27450982],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[image_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "\n",
    "We define a **Convolutional Neural Network (CNN)** using the Keras `Sequential` API. CNNs are particularly effective for image classification tasks like MNIST because they can learn spatial hierarchies of features.\n",
    "\n",
    "Here‚Äôs a breakdown of the architecture and why each layer is used in this order:\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Input(shape=(28, 28, 1))`  \n",
    "This defines the shape of the input image: 28√ó28 pixels, with 1 color channel (grayscale). Declaring an `Input` layer first is the modern practice in Keras, making the model easier to read and avoiding warnings.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Conv2D(28, kernel_size=(3, 3), activation='relu')`  \n",
    "This is the first convolutional layer. It applies 28 different 3√ó3 filters (kernels) to the input image to extract features like edges, curves, or small patterns.\n",
    "\n",
    "- **Why convolution first?**  \n",
    "  Convolutions scan the image with local filters to learn spatial features.\n",
    "- **Why ReLU?**  \n",
    "  The `ReLU` activation introduces non-linearity, helping the model learn complex patterns.\n",
    "- **Why 28 filters?**  \n",
    "  A small number of filters keeps the model lightweight while still expressive.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `MaxPooling2D(pool_size=(2, 2))`  \n",
    "After extracting features, we reduce the spatial dimensions using pooling. Max pooling picks the maximum value in each 2√ó2 window.\n",
    "\n",
    "- **Why pooling?**  \n",
    "  It reduces the number of parameters and computation, and also helps the model become more translation-invariant (robust to slight shifts in the digit‚Äôs position).\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Flatten()`  \n",
    "This layer converts the 2D output of the conv-pooling layers into a 1D vector, so we can pass it to fully connected (`Dense`) layers for classification.\n",
    "\n",
    "- **Why flatten now?**  \n",
    "  Because Dense layers expect a vector input ‚Äî this is the ‚Äúbridge‚Äù between convolution and classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Dense(64, activation='relu')`  \n",
    "This is a fully connected layer with 64 neurons. It learns abstract representations from the flattened features.\n",
    "\n",
    "- **Why Dense here?**  \n",
    "  Now that we‚Äôve extracted features, we need to learn patterns across the whole digit to classify it correctly.\n",
    "- **Why 64 units?**  \n",
    "  It‚Äôs a reasonable size that balances model capacity and training speed.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Dropout(0.2)`  \n",
    "Dropout randomly turns off 20% of the neurons during training to prevent overfitting.\n",
    "\n",
    "- **Why dropout now?**  \n",
    "  Fully connected layers are more prone to overfitting than convolutional layers, so regularization is added right after.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ `Dense(10, activation='softmax')`  \n",
    "The final classification layer. It outputs 10 probabilities corresponding to digits 0‚Äì9.\n",
    "\n",
    "- **Why 10 neurons?**  \n",
    "  Because we have 10 possible classes.\n",
    "- **Why softmax?**  \n",
    "  Softmax converts raw scores into probabilities that sum to 1, making it suitable for multi-class classification.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary  \n",
    "This architecture starts with convolutional layers to learn **spatial features**, and ends with dense layers to make a **prediction based on those features**. It's a common and effective CNN pattern for small image datasets like MNIST.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3DbGfDE5Yfgu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pdhye\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Building to Keras\n",
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential() #chosen Keras model\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape)) #convolution\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #pooling layer\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(64, activation=tf.nn.relu)) #dense layer relu\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax)) #dense layer softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compile & Train\n",
    "\n",
    "- **Optimizer:** Adam  \n",
    "- **Loss:** Sparse Categorical Crossentropy  \n",
    "- **Metrics:** Accuracy  \n",
    "\n",
    "We train for 20 epochs and will record total training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "94nX1XPcYfje"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9523 - loss: 0.1625\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.0928\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0686 \n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9839 - loss: 0.0522\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0444\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0401\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0318\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9899 - loss: 0.0294\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0264\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20ddf85e750>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compiling and fitting the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8M-S-eLcYfl8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06009311601519585, 0.9836000204086304]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation Results & Conclusions\n",
    "\n",
    "After training our CNN for 20 epochs, we evaluated its performance on the held-out test set:\n",
    "\n",
    "- **Test Loss:** 0.06 \n",
    "- **Test Accuracy:** 0.98\n",
    "\n",
    "**What this means:**  \n",
    "- A low test loss indicates the model‚Äôs predictions closely match the true labels.  \n",
    "- Achieving 98% accuracy shows the network correctly classifies nearly all handwritten digits.\n",
    "\n",
    "**Key Takeaways:**  \n",
    "- Our simple two-layer convolutional architecture effectively captures digit features.  \n",
    "- Dropout helped prevent overfitting, ensuring strong generalization to unseen data.  \n",
    "- At ~5 seconds per epoch, training is fast and scalable for similar image tasks.\n",
    "\n",
    "With these results, we have a robust baseline CNN for MNIST. Future improvements could include adding more convolutional blocks, using batch normalization, or incorporating data augmentation to push accuracy even higher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ATyjCTNTYDhS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#testing on test data\n",
    "image_index = 33 #choose random value up to 10000\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlGBZ5ho7v6D"
   },
   "source": [
    "# Prediction on sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def load_and_prepare_image(path, auto_invert=True):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "\n",
    "    if auto_invert:\n",
    "        mean_val = np.mean(img)\n",
    "        # If background is dark (low mean), it's likely black digit on white ‚Üí invert\n",
    "        if mean_val < 127:\n",
    "            img = 255 - img  # Invert only if image is dark\n",
    "\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    return img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set invert=True or False depending on your input image\n",
    "img_array = load_and_prepare_image(\"num3.jpg\",)\n",
    "\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted Digit: {predicted_class}\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_Ike (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
